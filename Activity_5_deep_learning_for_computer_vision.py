# -*- coding: utf-8 -*-
"""Seohee Activity 5: Deep Learning for Computer Vision.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ESU9TcMUXOTWnFLA5JX3wg8-NOiUa0Oh

#Deep Learning for Computer Vision

This will explore the the Tensorflow/Keras libraries for constructing and training deep learning networks. Convolutional Neural Networks for image classification, in this case. We will use Tensorflow as our main deep learning engine, and the Keras API on top of Tensorflow, because it is easier to use and more intuitive.
"""

import random
import numpy as np
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import matplotlib.pyplot as plt
import cv2
from sklearn.model_selection import train_test_split

"""## Learning the CIFAR10 dataset

The CIFAR10 dataset is a standard dataset for testing machine learning algorithms. For this you will not need any additional files, as the dataset can be downloaded from the web as needed.

This dataset contains 60,000 small images of vehicles, animals, and other objects. The network's task is to identify which category each image falls into.  We will print some representative images from the dataset in a code block below.

###Read and organize the training and validation data

The next section reads in and organizes the data. The `print` statements are just for exploration and could be commented out eventually.

Note that the data has already been split into training and validation data by Keras.

Every dataset is slightly different. In this case, we get a tuple of training and testing data. Each of those is, itself, a tuple containing the images and the corresponding labels for each image.
"""

# Get dataset from the Keras datasets
trainData, testData = datasets.cifar10.load_data()
(trainImages, trainLabels) = trainData
(testImages, testLabels) = testData

# Look at the size/shape of the training and test data
print(type(trainImages), type(trainLabels))
print(trainImages.shape, trainLabels.shape)
print(testImages.shape, testLabels.shape)

trainSize = len(trainLabels)
# Look at one image and one label
print(trainImages[0])
print(trainLabels[0])

"""###Exploring the data

The next section is optional, it just displays some of the data so you can see what the images look like. It chooses the images at random, and displays them in a 10 by 10 plot. Notice the low resolution of these images!
"""

# Labels are numbers between 0 and 9, indices into this list:
classNames = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog',
              'horse', 'ship', 'truck']

plt.figure(figsize=(10, 10))
for i in range(25):
    randIndex = random.randrange(trainSize)
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(trainImages[randIndex])
    # Each row in training labels is an array, not just a number
    outputNum = trainLabels[randIndex][0]
    strLabel = classNames[outputNum]
    plt.xlabel(strLabel)
plt.show()

"""### Preprocessing the data

Preprocessing can be as simple as converting the data to be in the range from 0.0 to 1.0, rather than 0 to 255 (that's what we're doing here), or as complex as data augmentation that adds random noise, warps and flips the data, or even performs computer vision operations like blurring, morphological filtering, thresholding and masking.
"""

# Normalize pixel values to be between 0 and 1
trainImages = trainImages / 255.0
testImages = testImages / 255.0

"""### Build the CNN model

The next section builds the model using the Keras interface. The model is a VGG-style of CNN: pairs of convolutional layers followed by max-pooling, with a pattern where the number of filters doubles each time, and the size is halved each time.

The first model, the one commented out, has a problem with overfitting, so the second model adds in drop-out layers to try to overcome the overfitting problem.

Drop-out layers randomly block certain nodes from the previous layer, forcing the network to not depend on any particular part, and forcing it to generalize.
"""

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))
model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Dropout(0.2))
model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(layers.MaxPooling2D((2, 2)))
# model.add(layers.Dropout(0.2))
model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(layers.MaxPooling2D((2, 2)))
#model.add(layers.Dropout(0.2))
model.add(layers.Flatten())
model.add(layers.Dense(128, activation='relu', kernel_initializer='he_uniform'))
#model.add(layers.Dropout(0.2))
model.add(layers.Dense(10, activation='softmax'))
model.summary()

"""### Configure, compile, and train

Next we prepare the model to run, setting up the learning algorithm, the error measure, and a performance metric, as well as passing in the test data for validation. And we then train the network!

**Note:** To improve the speed of training, select "Change Runtime Type" under the "Runtime" menu above, and ask for GPU hardware acceleration!ww
"""

# Prepare model and train
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(trainImages, trainLabels, epochs=3,
                    validation_data=(testImages, testLabels))

"""The next section displays the accuracy of the network on training and test data."""

# Show history, how training went and accuracy
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

plt.show()

"""---
##Milestone 1: Experiment with CIFAR10 task

Run the original model. Do you see underfitting (not learning the training set) or overfitting (accuracy stops increasing for validation set while it increases for training set). Try uncommenting some of the Dropout layers if you see overfitting, and change other parameters (add/remove layers, make layers smaller or bigger, change percentage for drop-out layers). Can you improve the performance?

Try the alternative below that uses *TensorBoard* to automatically store and display accuracy and loss.
"""

# Commented out IPython magic to ensure Python compatibility.
# Load the TensorBoard notebook extension
# %load_ext tensorboard

import datetime

# Clear any logs from previous runs
!rm -rf ./logs/

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)

model.fit(trainImages, trainLabels, epochs=10, validation_data=(testImages, testLabels),
          callbacks=[tensorboard_callback])

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs/fit

"""---
##Fashion Dataset

Next, we will import the dataset and set up training and test datasets. Training contains 60,000 images and their labels (0 through 9), and an additional 10,000 images and labels will be reserved for testing how well the network generalizes to new examples it never saw before. Using Keras’ own version of the dataset makes our data wrangling easy: it has already done the work of making training and test data. When you work with your own data, you will have much more to do!

"""

# This connects Colab to your Google Drive space
# from google.colab import drive
# drive.mount('/content/drive')

from google.colab.patches import cv2_imshow

"""##Reading in the data

The first step is always to figure out how to get the data into the system. Here we can use Keras itself to provide the dataset.
"""

# names for the categories 0 through 9 assigned to these images
classNames = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

(xTrain, yTrain), (xTest, yTest) = tf.keras.datasets.fashion_mnist.load_data()
trainSize = len(xTrain)

"""---
##Milestone 2: Accessing the data

Examine the size, shape, and contents of the four arrays, `xTrain`, `yTrain`, `xTest`, and `yTest`, by adding some print statements to see what shape the data is.

Adapt the code above for the CIFAR dataset, which selected random elements from the dataset to display. Display random selections from the training data, and attach the name of the category to each (use the numeric value in `yTrain` as an index into the `classNames` list.

"""

# Put your code for Milestone 2 here
ㅔ갸ㅜㅅ

"""---
##Preprocessing the Data

Preprocessing of a dataset of images can include the kinds of image processing we learned about earlier. Common techniques include equalizing the brightness across the dataset, using thresholds and masks, blurring, etc.. Data augmentation uses a variety of methods (warping, reversing, adding noise) to generate new images, for use when our dataset is too small.

In this case, we need to scale the data so that each pixel is a floating-point number between 0.0 and 1.0, instead of an integer between 0 and 255. We also need to reshape the data, where each entry is 28 by 28, so that it is 28 by 28 by 1, because the network expects that shape.

---
##Milestone 3 Implementing preprocessing

Use Numpy arithmetic to divide the big matrix of images by 255.0, and that will apply to every number in the matrix, all in one step.

To reshape the data, use the command shown below, and add a similar command to the `xTest` matrix.

After making these changes, add some print statements or another copy of the `plt` code from above that shows the dataset, and verify that it is the right shape and the right values.
"""

# Put your code for Milestone 3 here


# This next line changes the shape of the xTrain matrix
xTrain = xTrain.reshape((-1, 28, 28, 1))

"""---
##Setting up the CNN

Next, we need to tell the computer what the model is, the network, that we want to train. Keras provides some “classic” CNN architectures that you can use, but we’ll build a network from scratch.

The Activity 5 document has a picture of the CNN that we're going to build. Take a look at it!

---
##Milestone 4: Setting up the network

Read carefully through the description of the network in the Activity 5 document. Then, using the network above as inspiration, define the CNN that is described in the document.
* Be sure the first layer defines an `input_shape` as (28, 28, 1)
* To start, do not add Dropout layers, add those if you see overfitting later on


"""

# Put your Milestone 4 code here

"""---
## Compiling the model

We next need to tell the computer how to train the network, what to use as a measure of error and which algorithm to use to update the weights.

Tensorflow and Keras provide multiple training/optimization algorithms. You may choose a different one if you like, but you may just use Adam, the one we used in the first example.

Our output labels are stored as a number between 0 and 9, and not as one-hot vectors.* When the category is, instead, represented as numbers from 0 to whatever, we must use the ”Sparse Categorical Crossentropy” loss measure. And we should add in “accuracy” as a performance metric, as well as loss.

Loss computes the difference between the correct answer and the actual answer, treating the actual answers as percentages. Accuracy just counts how many samples produce the right answer, if we pick the highest probability answer from the network.

* (A one-hot vector would be a binary vector 10 long, where all the values are zero except the one that corresponds to the category an instance belongs to. For instance, if the label for an item was 4, the one-hot representation would be `[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]`.)

---
##Milestone 5: Compiling

Use the code from the example above as a model, and set up the training of the network! You can use Tensorboard to store and display the behavior of the network, if you want, or you could do it "by hand" as we did in the example before.
"""

# Put your code for Milestone 5 here

"""---
## Training the network

The code below will train the network for 20 epochs (the data in the training data will be presented 20 times, with learning after each individual instance presented).

Run this, and watch what happens to the `loss`, `val_loss`, `accuracy`, and `val_accuracy`.

As the training data is presented in one epoch, it computes the loss and accuracy on the training data: `loss` and `accuracy`. At the end of each epoch, it presents the validation data, with learning turned off, and reports on the loss and accuracy there: `val_loss` and `val_accuracy`.

If the performance on training and testing data diverges, there may be underfitting or overfitting!
"""

model.fit(xTrain, yTrain, epochs=20, validation_data=(xTest, yTest))

"""Once training is completed, you can run a test on your validation data, or any other data you have:"""

# Evaluate the model on test set
eval_loss, eval_acc = model.evaluate(xTest, yTest, verbose=2)

# Print test accuracy
print('\n', 'Test accuracy:', eval_acc)

"""---
## Milestone 6: Experiment and Analyze

Examine the results of the training. Is the network overfitting? If so, add dropout layers after each max-pooling layer, and after the first dense layer. Set the percentage to 0.2, 20%.

Experiment with this network. Instead of just reporting the overall final loss and accuracy, and the validation accuracy, try using the predict method of the model to collect all the results from the test data. You can count, for each category, how many images produce the correct answer as the highest probability, and perhaps how many have the correct answer in the top three answers produced by the network.

Alternatively, produce a [“confusion matrix,”](https://www.tensorflow.org/api_docs/python/tf/math/confusion_matrix) which will show where the network gets the most confused.

Does the error of the network follow any patterns? Are similar images confused with one another?

"""